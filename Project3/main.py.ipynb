{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pickle, gzip, numpy\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helper Functions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset, datasetSize):\n",
    "    featureArray = []\n",
    "    for i in range(datasetSize):\n",
    "        imageData = dataset[0][i]\n",
    "        featureArray.append(imageData)\n",
    "    return numpy.array(featureArray)\n",
    "\n",
    "def extract_targets(dataset, datasetSize):\n",
    "    targetArray = []\n",
    "    for i in range(datasetSize):\n",
    "        targetImage = dataset[1][i]\n",
    "        targetArray.append(targetImage)\n",
    "    return numpy.array(targetArray)\n",
    "\n",
    "def one_hot_encoding(dataset,datasetSize):\n",
    "    oneHotEncodedLabels = numpy.zeros((datasetSize, 10))\n",
    "    for i in range(datasetSize):\n",
    "        oneHotEncodedLabels[i][dataset[i]] = 1\n",
    "    return numpy.array(oneHotEncodedLabels)\n",
    "\n",
    "def random_initialization_of_array(arr, numOfRows, numOfCols):\n",
    "    for i in range(numOfRows):\n",
    "        for j in range(numOfCols):\n",
    "            arr[i][j] = numpy.random.randint(1,10)/10000;\n",
    "    return numpy.array(arr)\n",
    "\n",
    "def softmax_function(num, arr):\n",
    "    if(numpy.sum(numpy.exp(arr))!=0):\n",
    "        numerator = numpy.exp(num)\n",
    "        denominator = numpy.sum(numpy.exp(arr))\n",
    "        return (numerator/denominator)\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistTrainSize = 50000\n",
    "mnistValidateSize = 10000\n",
    "mnistTestSize = 10000\n",
    "numOfClasses = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing MNIST Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training, validation and testing dataset from mnist pickle file\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, validation_set, test_set = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "# Processing the dataset for creating numpy array that contains features\n",
    "mnistFeaturesTrain = extract_features(train_set,mnistTrainSize) #features in training set\n",
    "mnistFeaturesValidate = extract_features(validation_set,mnistValidateSize) #features in validation set\n",
    "mnistFeaturesTest = extract_features(test_set,mnistTestSize) #features in testing set\n",
    "\n",
    "# Processing the dataset for creating numpy array that contains target lables\n",
    "mnistTargetTrain = extract_targets(train_set,mnistTrainSize) #target labels in training set\n",
    "mnistTargetValidate = extract_targets(validation_set,mnistValidateSize) #taret labels in validation set\n",
    "mnistTargetTest = extract_targets(test_set,mnistTestSize) #target labels in testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MNIST Dataset using Softmax Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of target labels\n",
    "trainingLabels = one_hot_encoding(mnistTargetTrain, mnistTrainSize)\n",
    "validationLabels = one_hot_encoding(mnistTargetValidate, mnistValidateSize)\n",
    "testingLabels = one_hot_encoding(mnistTargetTest, mnistTestSize)\n",
    "\n",
    "# randomly initializing weight vector\n",
    "weights = numpy.zeros((784,numOfClasses))\n",
    "weights = random_initialization_of_array(weights, 784, numOfClasses)\n",
    "\n",
    "# randomly initializing weight vector\n",
    "bias = numpy.zeros((1,10))\n",
    "bias = random_initialization_of_array(bias, 1, numOfClasses)\n",
    "\n",
    "# weight vector with bias\n",
    "weights = numpy.concatenate((bias, weights))\n",
    "\n",
    "# feature vectors with \"ones\"\n",
    "trainingFeatures = numpy.insert(mnistFeaturesTrain, 0, 1, axis=1)\n",
    "validationFeatures = numpy.insert(mnistFeaturesValidate, 0, 1, axis=1)\n",
    "testingFeatures = numpy.insert(mnistFeaturesTest, 0,1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRADIENT DESCENT SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "learningRate = 0.4\n",
    "Lambda = 0.5\n",
    "epochs = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set accuracy =  91.07\n",
      "test set accuracy =  90.89\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classesSLR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2ee032556767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mconfusionMatrixSLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnistTargetTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassesSLR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfusionMatrixSLR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classesSLR' is not defined"
     ]
    }
   ],
   "source": [
    "# Updating weights for all classes over entire training dataset\n",
    "for i in range(epochs):\n",
    "    # creating net input Z\n",
    "    Z = numpy.dot(trainingFeatures, weights)\n",
    "    \n",
    "    #creating the softmax activation vector\n",
    "    softmax = []\n",
    "    count = 0\n",
    "    for row in Z:\n",
    "        count = count + 1\n",
    "        data = numpy.zeros((1,10))\n",
    "        for i in range(numOfClasses):\n",
    "            data[0][i] = softmax_function(row[i], row)\n",
    "        softmax.append(data)\n",
    "    softmax = numpy.array(softmax)\n",
    "    \n",
    "    # calculating cost derivative - Cost is Cross Entropy\n",
    "    costDerivative = numpy.zeros((785,numOfClasses))\n",
    "    for rowTrain, rowSoftmax, rowLabel in zip(trainingFeatures, softmax, trainingLabels):\n",
    "        rowTrain = rowTrain.reshape(1,785)\n",
    "        costDerivative = numpy.add(numpy.dot(numpy.transpose(rowTrain),numpy.subtract(rowLabel,rowSoftmax)), costDerivative)\n",
    "    costDerivative = costDerivative/mnistTrainSize\n",
    "    #costDerivative = costDerivative + Lambda*weights\n",
    "    weights = numpy.subtract(weights, numpy.dot(learningRate, numpy.dot(-1,costDerivative)))\n",
    "\n",
    "# calculating net input for validation dataset\n",
    "Zvalidation = numpy.dot(validationFeatures, weights)\n",
    "\n",
    "#creating the softmax activation vector for validation dataset\n",
    "softmaxV = []\n",
    "count = 0\n",
    "for row in Zvalidation:\n",
    "    count = count + 1\n",
    "    data = numpy.zeros((1,10))\n",
    "    for i in range(numOfClasses):\n",
    "        data[0][i] = softmax_function(row[i], row)\n",
    "    softmaxV.append(data)\n",
    "softmaxV = numpy.array(softmaxV)\n",
    "\n",
    "matchV = 0\n",
    "for row, row1 in zip(softmaxV, validationLabels):\n",
    "    t = numpy.argmax(row)\n",
    "    v = numpy.argmax(row1)\n",
    "    if(t == v):\n",
    "        matchV = matchV + 1\n",
    "accuracyV = (float(matchV)*100)/mnistValidateSize\n",
    "\n",
    "# calculating net input for test dataset\n",
    "Ztest = numpy.dot(testingFeatures, weights)\n",
    "\n",
    "#creating the softmax activation vector for validation dataset\n",
    "softmaxT = []\n",
    "count = 0\n",
    "for row in Ztest:\n",
    "    count = count + 1\n",
    "    data = numpy.zeros((1,10))\n",
    "    for i in range(numOfClasses):\n",
    "        data[0][i] = softmax_function(row[i], row)\n",
    "    softmaxT.append(data)\n",
    "softmaxT = numpy.array(softmaxT)\n",
    "\n",
    "# calculating accuracy for test data\n",
    "matchT = 0\n",
    "for row, row1 in zip(softmaxT, testingLabels):\n",
    "    t = numpy.argmax(row)\n",
    "    v = numpy.argmax(row1)\n",
    "    if(t == v):\n",
    "        matchT = matchT + 1\n",
    "accuracyT = (float(matchT)*100)/mnistTestSize\n",
    "\n",
    "print(\"validation set accuracy = \", accuracyV)\n",
    "print(\"test set accuracy = \", accuracyT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "[958   0   2   2   1   4   9   1   3   0]\n",
      "[   0 1103    2    4    1    2    4    1   18    0]\n",
      "[ 11   7 897  15  15   1  15  18  44   9]\n",
      "[  5   1  20 902   1  31   4  15  21  10]\n",
      "[  1   4   6   1 909   0  10   1   8  42]\n",
      "[ 11   4   4  42  11 750  16  10  36   8]\n",
      "[ 14   3   5   2  13  12 904   1   4   0]\n",
      "[  3  19  26   5  10   0   0 927   3  35]\n",
      "[  9   9   9  28   8  22  14  14 848  13]\n",
      "[ 11   8   5  11  42  12   0  23   6 891]\n"
     ]
    }
   ],
   "source": [
    "# predicted classes for test data\n",
    "classesSLR = [] \n",
    "for row in softmaxT:\n",
    "    classesSLR.append(numpy.argmax(row))\n",
    "classesSLR=numpy.array(classesSLR)\n",
    "print(classesSLR)\n",
    "\n",
    "#confusion matrix\n",
    "confusionMatrixSLR = confusion_matrix(mnistTargetTest, classesSLR)\n",
    "for row in confusionMatrixSLR:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MNIST Dataset using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "kernelValue = 'rbf'\n",
    "Cvalue = 2\n",
    "gammaValue = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841\n",
      "0.9835\n",
      "[7 2 1 ... 4 5 6]\n",
      "[974   0   1   0   0   1   1   1   2   0]\n",
      "[   0 1129    2    1    0    1    0    1    1    0]\n",
      "[   4    0 1014    0    1    0    1    7    4    1]\n",
      "[  0   0   2 997   0   2   0   4   3   2]\n",
      "[  0   0   2   0 966   0   4   0   1   9]\n",
      "[  2   0   0   8   1 872   4   0   3   2]\n",
      "[  4   2   0   0   2   3 946   0   1   0]\n",
      "[   0    5    8    1    1    0    0 1005    1    7]\n",
      "[  3   0   2   4   4   2   1   2 953   3]\n",
      "[  4   2   1   6   8   2   0   6   1 979]\n"
     ]
    }
   ],
   "source": [
    "SVMclassifier = SVC(kernel=kernelValue, C = Cvalue, gamma = gammaValue)\n",
    "SVMclassifier.fit(mnistFeaturesTrain, mnistTargetTrain)\n",
    "print(SVMclassifier.score(mnistFeaturesValidate, mnistTargetValidate))\n",
    "print(SVMclassifier.score(mnistFeaturesTest, mnistTargetTest))\n",
    "classesSVM = SVMclassifier.predict(mnistFeaturesTest)\n",
    "print(classesSVM)\n",
    "confusionMatrixSVM = confusion_matrix(mnistTargetTest, classesSVM)\n",
    "for row in confusionMatrixSVM:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MNIST Dataset using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "nEstimators = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set 0.971\n",
      "test set 0.9684\n",
      "[7 2 1 ... 4 5 6]\n",
      "[971   0   1   0   0   3   1   1   3   0]\n",
      "[   0 1122    2    2    0    2    3    0    3    1]\n",
      "[  6   0 997   8   3   0   3   8   7   0]\n",
      "[  0   0   7 975   0   8   0  10   7   3]\n",
      "[  1   0   0   0 952   0   5   1   5  18]\n",
      "[  3   0   0  14   3 858   4   1   6   3]\n",
      "[  5   3   0   0   4   4 939   0   3   0]\n",
      "[  1   3  19   1   2   0   1 991   2   8]\n",
      "[  4   1   5   8   7   4   5   6 923  11]\n",
      "[  6   4   1  11  13   1   0   4  13 956]\n"
     ]
    }
   ],
   "source": [
    "RFclassifier = RandomForestClassifier(n_estimators = nEstimators)\n",
    "RFclassifier.fit(mnistFeaturesTrain, mnistTargetTrain)\n",
    "print(\"validation set\", RFclassifier.score(mnistFeaturesValidate, mnistTargetValidate))\n",
    "print(\"test set\", RFclassifier.score(mnistFeaturesTest, mnistTargetTest))\n",
    "classesRF = RFclassifier.predict(mnistFeaturesTest)\n",
    "print(classesRF)\n",
    "confusionMatrixRF = confusion_matrix(mnistTargetTest, classesRF)\n",
    "for row in confusionMatrixRF:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MNIST Dataset using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOWNLOADING AND PARTITIONING MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "y_train = keras.utils.to_categorical(y_train, numOfClasses)\n",
    "y_test = keras.utils.to_categorical(y_test, numOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "unitsLayer1 = 64\n",
    "activationLayer1 = 'sigmoid'\n",
    "activationLayer2 = 'softmax'\n",
    "optimizerValue = 'Adadelta'\n",
    "batchSize = 128\n",
    "epochsValue = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set accuracy  [0.907666666507721, 0.9221666668256124, 0.9298333338101705, 0.9350000004768372, 0.940833333492279, 0.9448333338101705, 0.9445, 0.9430000001589457, 0.9448333331743877, 0.9484999996821085, 0.9491666663487752, 0.9521666669845581, 0.9524999998410543, 0.9528333330154419, 0.9544999998410543, 0.950833333492279, 0.9559999996821086, 0.9558333331743876, 0.9561666669845581, 0.9544999996821085]\n",
      "test set loss =  0.18010250396504998 test set accuracy =  0.9459\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "image_size = 784\n",
    "model = Sequential()\n",
    "model.add(Dense(units=unitsLayer1, activation=activationLayer1, input_shape=(image_size,)))\n",
    "model.add(Dense(units=numOfClasses, activation=activationLayer2))\n",
    "model.compile(optimizer=optimizerValue, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=batchSize, epochs=epochsValue, verbose=False, validation_split=0.1)\n",
    "print(\"validation set accuracy \", history.history['val_acc'])\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"test set loss = \", loss, \"test set accuracy = \" , accuracy)\n",
    "classesNN = model.predict_classes(x_test, batch_size=batchSize)\n",
    "print(classesNN)\n",
    "confusionMatrixNN = confusion_matrix(mnistTargetTest, classesNN)\n",
    "for row in confusionMatrixNN:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing USPS Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-numpy.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing USPS Dataset on all the four classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 10)\n",
      "NN USPS test set accuracy =  0.21896094804740238\n",
      "SLR USPS test set accuracy 9.880494024701235\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "print(\"SVM USPS test data set accuracy = \", SVMclassifier.score(USPSMat, USPSTar))\n",
    "\n",
    "# Neural Network classifier\n",
    "USPSMat1 = numpy.array(USPSMat)\n",
    "USPSTar1= numpy.array(USPSTar)\n",
    "USPSTar1 = keras.utils.to_categorical(USPSTar1, numOfClasses)\n",
    "print(USPSTar1.shape)\n",
    "lossU, accuracyU = model.evaluate(USPSMat1, USPSTar1, verbose=False)\n",
    "print(\"NN USPS test set accuracy = \", accuracyU)\n",
    "\n",
    "# Random Forest classifier\n",
    "print(\"RF USPS test set accuracy\", RFclassifier.score(USPSMat, USPSTar))\n",
    "\n",
    "# Softmax Logistic Regression classifier\n",
    "USPSMat = numpy.insert(USPSMat, 0, 1, axis=1)\n",
    "# calculating net input for test dataset\n",
    "ZtestU = numpy.dot(USPSMat, weights)\n",
    "\n",
    "#creating the softmax activation vector for validation dataset\n",
    "softmaxTU = []\n",
    "count = 0\n",
    "for row in ZtestU:\n",
    "    count = count + 1\n",
    "    data = numpy.zeros((1,10))\n",
    "    for i in range(numOfClasses):\n",
    "        data[0][i] = softmax_function(row[i], row)\n",
    "    softmaxTU.append(data)\n",
    "softmaxTU = numpy.array(softmaxTU)\n",
    "matchUT = 0\n",
    "for row, row1 in zip(softmaxTU, USPSTar):\n",
    "    t = numpy.argmax(row)\n",
    "    v = numpy.argmax(row1)\n",
    "    if(t == v):\n",
    "        matchUT = matchUT + 1\n",
    "accuracyUT = (float(matchUT)*100)/len(USPSTar)\n",
    "print(\"SLR USPS test set accuracy\", accuracyUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Results of the 4 classifiers - Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.49\n"
     ]
    }
   ],
   "source": [
    "matchFinal = 0\n",
    "for i in range(mnistTestSize):\n",
    "    # matrix d which has 4 columns for the 4 classifiers and 10 rows for the 10 classes. Each cell in d\n",
    "    # contains 1 if a classfier predicts the corresponding class for that datapoint. Every datapoint will have a d matrix.\n",
    "    d = numpy.zeros((numOfClasses, 4))\n",
    "    d[classesSLR[i]-1][0] = 1\n",
    "    d[classesSVM[i]-1][0] = 1\n",
    "    d[classesRF[i]-1][0] = 1\n",
    "    d[classesNN[i]-1][0] = 1\n",
    "    # matrix rankForClass contains the number of votes a particular class got by the four classifiers i.e how many classifiers \n",
    "    # voted for that particular class. So, each cell contains the sum of the corresponding rows of d. Each row in d represents\n",
    "    # a class.\n",
    "    rankForClass = numpy.zeros((numOfClasses))\n",
    "    index = 0\n",
    "    for row in d:\n",
    "        rankForClass[index] = numpy.sum(row)\n",
    "        index = index + 1\n",
    "    # the index of rankForClass (added 1 as index starts from 0) which has the highest votes is selected as final prediction\n",
    "    finalPredictedClass = numpy.argmax(rankForClass) + 1\n",
    "   \n",
    "    # to find the number of predictions that match with the actual predictions\n",
    "    if(finalPredictedClass == mnistTargetTest[i]):\n",
    "        matchFinal = matchFinal + 1\n",
    "\n",
    "# finding accuracy\n",
    "accuracyFinal = (float(matchFinal)*100)/mnistTestSize\n",
    "print(accuracyFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
